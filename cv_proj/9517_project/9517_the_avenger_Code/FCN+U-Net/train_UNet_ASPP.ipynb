{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import T_Dataset\n",
    "from util import EDMLoss,AverageMeter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from UNet import UNet, UNetWithASPP\n",
    "from FCN import  FCN, FCNWithASPP\n",
    "\n",
    "\n",
    "def adjust_learning_rate(params, optimizer, epoch):\n",
    "    lr = params.init_lr * (0.1 ** (epoch // 10))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def criterion_s(inputs, target):\n",
    "    losses = nn.functional.cross_entropy(inputs, target, ignore_index=255)\n",
    "    # stop\n",
    "    return losses\n",
    "\n",
    "def create_data_part(opt):\n",
    "    train_csv_path =  'train_quarter.csv'\n",
    "    val_csv_path = 'valid.csv'\n",
    "    test_csv_path = 'valid.csv'\n",
    "\n",
    "    train_ds = T_Dataset(train_csv_path, opt.path_to_images, if_train = True )\n",
    "    val_ds = T_Dataset(val_csv_path, opt.path_to_images, if_train = False )\n",
    "    test_ds = T_Dataset(test_csv_path, opt.path_to_images, if_train=False )\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=opt.batch_size, num_workers=opt.num_workers, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=int(opt.batch_size/2), num_workers=opt.num_workers, shuffle=False, drop_last=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=opt.batch_size, num_workers=opt.num_workers, shuffle=False, drop_last=True)\n",
    "\n",
    "    return train_loader, val_loader,test_loader\n",
    "\n",
    "def train(opt,model, loader, optimizer, criterion, writer=None, global_step=None, name=None):\n",
    "    model.train()\n",
    "    train_losses = AverageMeter()\n",
    "\n",
    "    for idx, (x,  mask) in enumerate(tqdm(loader)):\n",
    "        x = x.to(opt.device)\n",
    "        mask = mask.long()\n",
    "        mask=mask.to(opt.device)\n",
    "        pred = model(x)\n",
    "        #print(\"y:\",y)\n",
    "        #print(\"pred:\",pred)\n",
    "        #print(\"mask shape:\",mask.shape)\n",
    "        #print(\"pred shape:\",pred.shape)\n",
    "        #print(\"pred:\", pred.argmax(1).unique())\n",
    "        #print(\"mask:\", mask.unique())\n",
    "        #stop\n",
    "        #print(\"x scale:\", torch.min(x), torch.max(x))\n",
    "        #print(\"target_img scale:\", torch.min(target_img), torch.max(target_img))\n",
    "        #print(\"pred scale:\", torch.min(pred), torch.max(pred))\n",
    "\n",
    "        #save_image(x[0], 'x.jpg')\n",
    "        #save_image(target_img[0], 'target_img.jpg')\n",
    "        #stop\n",
    "\n",
    "        loss=criterion(pred, mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.update(loss.item(), x.size(0))\n",
    "    print(\"train loss(target_img-pred):\", train_losses.avg)\n",
    "\n",
    "    return train_losses.avg\n",
    "\n",
    "def validate(opt,model, loader, criterion, writer=None, global_step=None, name=None):\n",
    "    model.eval()\n",
    "    validate_losses = AverageMeter()\n",
    "    true_score = []\n",
    "    pred_score = []\n",
    "    Ssim = 0\n",
    "    psnr_value = 0\n",
    "    flag=0\n",
    "\n",
    "    for idx, (x, mask) in enumerate(tqdm(loader)):\n",
    "        x = x.to(opt.device)\n",
    "        mask = mask.long()\n",
    "        mask = mask.to(opt.device)\n",
    "\n",
    "        pred = model(x)\n",
    "\n",
    "        #save_image(pred[0], 'pred.jpg')\n",
    "        #save_image(target_img[0], 'target_img.jpg')\n",
    "        #stop\n",
    "        loss = criterion(pred, mask)\n",
    "        validate_losses.update(loss.item(), x.size(0))\n",
    "\n",
    "        #Ssim = Ssim + torch.mean(\n",
    "        #    ssim(pred.detach().to(\"cpu\"), target_img.detach().to(\"cpu\"), data_range=1, size_average=False))\n",
    "        #for i in range(pred.shape[0]):\n",
    "        #    psnr_value = psnr_value+calculate_psnr(pred[i], target_img[i])\n",
    "        #batch_size = x.shape[0]\n",
    "        #flag = flag+1\n",
    "\n",
    "    #print(\"psnr:\", psnr_value/(batch_size*flag))\n",
    "    #Ssim = Ssim / flag\n",
    "    #print(\"ssim:\", Ssim.item())\n",
    "    print(\"val loss:\",validate_losses.avg)\n",
    "    return validate_losses.avg, 0, 0, 0\n",
    "\n",
    "\n",
    "def start_train(opt):\n",
    "\n",
    "    train_loader, val_loader, test_loader = create_data_part(opt)\n",
    "\n",
    "    model = UNetWithASPP()\n",
    "    model_path = 'ckpt/UNetWithASPP_epoch_8_train_loss_0.27257630599267557_val_loss0.2381819197171026.pth'\n",
    "    model.load_state_dict(torch.load(model_path, map_location='cuda:0'))\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=opt.init_lr)\n",
    "    criterion = criterion_s\n",
    "    #criterion.to(opt.device)\n",
    "    model = model.to(opt.device)\n",
    "    writer = None\n",
    "\n",
    "    for e in range(1):\n",
    "        adjust_learning_rate(opt, optimizer, e)\n",
    "        train_loss = train(opt, model=model, loader=train_loader,\n",
    "                           optimizer=optimizer, criterion=criterion,\n",
    "                           writer=writer, global_step=len(train_loader) * e,\n",
    "                           name=\"_by_batch\")\n",
    "        val_loss, vacc, ssim_val, psnr_val = validate(opt, model=model,\n",
    "                                               loader=val_loader, criterion=criterion,\n",
    "                                               writer=writer, global_step=len(val_loader) * e,\n",
    "                                               name=\"_by_batch\")\n",
    "\n",
    "        model_name = f\"UNetWithASPP_epoch_{e}_train_loss_{train_loss}_val_loss{val_loss}.pth\"\n",
    "        torch.save(model.state_dict(), model_name)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T12:07:32.076189900Z",
     "start_time": "2024-11-11T12:07:32.069909700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 75/82 [07:15<01:14, 10.61s/it]"
     ]
    }
   ],
   "source": [
    "print(\"_\" * 100)\n",
    "import easydict\n",
    "import warnings\n",
    "\n",
    "option = easydict.EasyDict({\n",
    "    \"batch_size\": 100,\n",
    "    \"train_steps\": 1000,\n",
    "\n",
    "    'path_to_images': 'D:/turtles-data/data/',\n",
    "\n",
    "    'init_lr': 0.00003,\n",
    "    'num_epoch': 100,\n",
    "    'batch_size': 16,\n",
    "    'num_workers': 0,\n",
    "    'gpu_id': '0'\n",
    "})\n",
    "#import warnings\n",
    "f = open('log_test.txt', 'w')\n",
    "opt = option\n",
    "opt.device = torch.device(\"cuda:0\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "start_train(opt)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-11-11T12:07:32.610246800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
